% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summarize_rubias_base_eval.r
\name{summarize_rubias_base_eval}
\alias{summarize_rubias_base_eval}
\title{Summarize \code{rubias} Baseline Evaluation Tests}
\usage{
summarize_rubias_base_eval(
  rubias_output = NULL,
  mixvec,
  sample_sizes,
  method = c("MCMC", "PB", "both")[1],
  path = "rubias/output",
  alpha = 0.1,
  burn_in = 5000,
  threshold = 5e-07,
  ncores = 4,
  file_type = c("fst", "csv")[1]
)
}
\arguments{
\item{mixvec}{A character vector of test mixture names.}

\item{sample_sizes}{A tibble produced by \code{\link[=base_eval_sample_sizes]{base_eval_sample_sizes()}} containing the following variables:
\code{test_group}, \code{scenario}, \code{repunit}, and \code{samps}.}

\item{method}{A character vector of length 1 indicating the \pkg{rubias} output to summarize:
"MCMC" (summarize MCMC output), "PB" (summarize bias corrected output), "both" (summarize both outputs); (default = "MCMC)}

\item{path}{A character vector of where to find output from each mixture as a .csv or .fst file (created by \code{\link[=run_rubias_base_eval]{run_rubias_base_eval()}};
default is "rubias/output").}

\item{alpha}{A numeric vector of length 1 specifying credibility intervals (default is 0.1, which gives 90\% CIs (i.e., 5\% and 95\%)).}

\item{burn_in}{A numeric vector of length 1 specifying how many sweeps were used for burn_in in \code{\link[=run_rubias_base_eval]{run_rubias_base_eval()}}
(default = 5000).}

\item{threshold}{A numeric vector of length 1 specifying how low stock comp is before assume 0, used for \code{P=0} calculation, (default = 5e-7).}

\item{ncores}{An optional numeric value for the number of cores to use in a \pkg{foreach} \verb{\%dopar\%} loop (default = 4).
If the number of cores exceeds the number on your device (\code{\link[parallel:detectCores]{parallel::detectCores()}}), then all cores will be used. Note that \code{ncores} is
only used if \code{method = "both"}.}

\item{file_type}{the file type of the mixture output files .fst (default and faster) or .csv files.}
}
\value{
A list with the following 2 components:
\itemize{
\item \code{estimates}: a tibble with 11 columns containing all group-level stock proportion output:
\itemize{
\item \code{test_group}: \code{repunit} being tested
\item \code{scenario}: stock proportion of \code{repunit} being tested
\item \code{repunit}: group name
\item \code{mean}: mean posterior of stock proportion
\item \code{sd}: sd of posterior of stock proportion
\item \code{lo5CI}: lower 5\% CI from posterior of stock proportion
\item \code{hi95CI}: upper 95\% CI from posterior of stock proportion
\item \code{P=0}: proportion of posterior with stock proportion < \code{threshold} (i.e., 0)
\item \code{true_proportion}: the true stock proportion in  the scenario
\item \code{total_samples}: mixture scenario sample size
\item \code{method}: \code{rubias} method ("MCMC" or "PB")
}
\item \code{summary_stats}: a tibble with 6 columns containing mixture summary statistics for each group tested:
\itemize{
\item \code{method}: \code{rubias} method ("MCMC" or "PB")
\item \code{test_group}: \code{repunit} being tested
\item \code{RMSE}: root mean squared error of mean stock proportions
\item \code{Mean_Bias}: mean bias (estimate - true) among all test mixtures for a given \code{test_group}
\item \code{90_within}: the abs(90\% CI) of the residuals (i.e., 90\% of point estimates were within d distance of the true proportion)
\item \code{Within_Interval}: the proportion of tests where the CI contained the true proportion
}
}
}
\description{
Thus function summarizes \pkg{rubias} output from baseline
evaluation tests after running \code{\link[=run_rubias_base_eval]{run_rubias_base_eval()}}.
}
\details{
Thus function is the final step in baseline evaluations tests using \pkg{rubias}. The normal workflow uses: \code{\link[=base_eval_sample_sizes]{base_eval_sample_sizes()}}
to determine test mixture sample sizes, then \code{\link[=create_rubias_base_eval]{create_rubias_base_eval()}} generates the necessary \pkg{rubias} files, which
are then analyzed/run in parallel by \code{\link[=run_rubias_base_eval]{run_rubias_base_eval()}} to create output files, and finally summarized by \code{\link[=summarize_rubias_base_eval]{summarize_rubias_base_eval()}}.
This function has the option of summarizing fst or csv mixture output files. fst files are compressed so they read into R faster, which speeds up the mixture summary process.
}
\examples{
\dontrun{
 
path <- "V:/Analysis/5_Coastwide/Sockeye/IYS_2022_MSA/rubias/Evaluating IYS sockeye baseline groups/rubias/output"

sample_sizes <- readRDS("V:/Analysis/5_Coastwide/Sockeye/IYS_2022_MSA/rubias/Evaluating IYS sockeye baseline groups/output/sample_sizes.rds")

mixvec <- suppressWarnings(tibble::tibble(files = list.files(path, pattern = "_repunit_trace.csv")) \%>\% 
                             tidyr::separate(files, into = c("mixture", NA), sep = "_repunit_trace.csv") \%>\% 
                             dplyr::pull(mixture))

GCLr::summarize_rubias_base_eval(mixvec = mixvec, path = path, sample_sizes = sample_sizes, ncores = parallel::detectCores())

}

}
\seealso{
\code{\link[=base_eval_sample_sizes]{base_eval_sample_sizes()}}
\code{\link[=create_rubias_base_eval]{create_rubias_base_eval()}}
\code{\link[=run_rubias_base_eval]{run_rubias_base_eval()}}
\code{\link[rubias:rubias]{rubias::rubias()}}
}
